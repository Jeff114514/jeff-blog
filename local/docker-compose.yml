# 本地端 Docker Compose 配置
version: '3.8'

services:
  # MySQL数据库
  mysql:
    image: mysql:8.0
    container_name: blog_mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: blog123456
      MYSQL_DATABASE: blog_db
      MYSQL_CHARACTER_SET_SERVER: utf8mb4
      MYSQL_COLLATION_SERVER: utf8mb4_unicode_ci
      TZ: Asia/Shanghai
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
      - ./mysql/init:/docker-entrypoint-initdb.d
    command: 
      - --default-authentication-plugin=mysql_native_password
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
    networks:
      - blog-network

  # 后端服务
  backend:
    build: ./backend
    container_name: blog_backend
    restart: always
    depends_on:
      - mysql
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/blog_db?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
      SPRING_DATASOURCE_USERNAME: root
      SPRING_DATASOURCE_PASSWORD: blog123456
      AI_LOCAL_MODEL_URL: http://host.docker.internal:11434/api/generate
    ports:
      - "8080:8080"
    networks:
      - blog-network
    volumes:
      - backend-logs:/app/logs

  # 前端服务
  frontend:
    build: ./frontend
    container_name: blog_frontend
    restart: always
    ports:
      - "3000:80"
    networks:
      - blog-network
    depends_on:
      - backend

  # vLLM AI服务（使用本地模型）
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: always
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=Qwen3-4B-I-chat
      - MAX_MODEL_LEN=4096
      - GPU_MEMORY_UTILIZATION=0.8
    volumes:
      - D:/code/llm/wyh/llm/Qwen3/Qwen3-4B-I-chat:/models/Qwen3-4B-I-chat:ro
      - vllm-cache:/root/.cache
      - ./config:/config:ro
    networks:
      - blog-network
    command: >
      --model /models/Qwen3-4B-I-chat
      --host 0.0.0.0
      --port 8000
      --max-model-len 4096
      --gpu-memory-utilization 0.85
      --tensor-parallel-size 1
      --trust-remote-code
      --tokenizer /models/Qwen3-4B-I-chat
      --config /config/vllm_config.json
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # FRP客户端
  frpc:
    image: snowdreamtech/frpc:latest
    container_name: frpc
    restart: always
    volumes:
      - ./frp/frpc.ini:/etc/frp/frpc.ini
    networks:
      - blog-network
    command: -c /etc/frp/frpc.ini

volumes:
  mysql-data:
    driver: local
  backend-logs:
    driver: local
  vllm-cache:
    driver: local

networks:
  blog-network:
    driver: bridge

